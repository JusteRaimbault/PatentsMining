\input{header.tex}


\title{
An Hypernetwork Approach to Accurately Measure Technological Innovation
\bigskip\\
\textit{Methods and Results}
}
\author{\noun{J. Raimbault}$^{1,2}$ and \noun{A. Bergeaud}$^{3}$\medskip\\
$^{1}$ UMR CNRS 8504 G{\'e}ographie-cit{\'e}s\\
$^{2}$ UMR-T IFSTTAR 9403 LVMT\\
$^{3}$ London School of Economics
}
\date{}


\maketitle

\justify


\begin{abstract}
This working paper details technical methods used in the project and gives a first overview of results.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%

\textit{See project Proposal}


%%%%%%%%%%%%%%%%%%%%
\section{Methods}
%%%%%%%%%%%%%%%%%%%%




% Taken from Technical Details section of proposal 
% -> develop more precisely if needed



\paragraph{Originality Measures}

The originality measure is
defined by Hall \textit{et al.} (2001)~\cite{Hall2001} as
\[
O_{i}=1-\sum_{j=1}^{n_{i}}{c_{i,j}^{2}}
\]
where $c_{i,j}$is the percentage of citations made by patent $i$ to a patent in class $j$ out of
$n_{i}$ technological classes to which patent $i$ belongs. If the scope of
technologies which the patent uses and cites is large, then the originality
measure will be high. Radicalness is more difficult to define. It is
constructed in the same way as the originality index but here we only consider
the technology classes of patents cited by patent $i$ but to which patent $i$
does not belong. These two indicators are good proxies and great start to estimate if a patent is protecting a new product that can hardly be classified into the official technological field space.



\paragraph{Citation Network}

We define a binary relationship between each pair of patents $Cit(i, j) = 1$ if j cites i or i cites j, otherwise $Cit(i, j) = 0$. 

\paragraph{Technological Class Network}

For each patent i, let $B_i$ be the set of technological class of i. We then define a relationship between each pair i and j as 2 times the number of technological class in common divided by the total number of class of i and j. 
\[
Class(i,j) = 2\frac{\left\vert{B_i\cap B_j}\right\vert}{\left\vert{B_i}\right\vert+\left\vert{B_j}\right\vert}
\]

Thus, if two patents have no class in common, $Class(i,j)=0$ while if the two patents are exactly identical in terms of their sets of technologial class $Class(i,j)=1$.


\paragraph{Computation of the Technological Network}

With a number of patents of magnitude $10^6$, it is not considerable in memory and in time to compute pairwise distances on all patents. Fortunately, distance matrix is relatively sparse and non trivial proximities  (i.e. where patents have more than one class in common) can be computed through an efficient set intersection and difference implementation.

More precisely, let $n = \left|\mathcal{P}\right|$ the number of patents. classes are constructed in $O(n)$ from file giving patents classes, and then sorted in $\Theta (\sum_k{\left|\mathcal{C}_k\right|\cdot \log{\left|\mathcal{C}_k\right|}})$ with $\mathcal{C}_k$ the classes. The number of classes $K$ being fixed, it simplifies into a $O(n\log{n})$. This sorting allows to compute overlaps and differences between classes in linear time


%%%%%%%%%%%%%%%%%%%%
\subsection{Semantic Network}

\paragraph{Significant Keywords extraction procedure}

We first assign to a patent $p \in \mathcal{P}$ a set of significant keywords $K(p)\in \bigcup_{n\in \mathbb{N}} {\mathcal{A}^{\ast}}^n$, that are precisely extracted through a procedure similar to the one detailed in~\cite{chavalarias2013phylomemetic}, consisting in the following steps
\begin{enumerate}
\item Text parsing and tokenizing.
\item Part-of-speech tagging, normalization.
\item Stem extraction and multi-stems constructions.
\item Relevant multi-stems filtering.
\end{enumerate}

Text processing operations are implemented in \texttt{python} in order to use the \texttt{nltk} library~\cite{} % cite nltk
which is highly ergonomic and supports most advanced state-of-the-art natural language processing operations. Source code is openly available on the repository of the project\footnote{at \texttt{url}}.
% TODO je suis pour ouvrir le repo une fois qu'on aura la majorité du taf faite, je sais pas ce que t'en penses ? c'est une nécessité pour ouverture et reproducibilité ; sans ça aucune valeur à ce qu'on prétend dans le papelard.
Steps one to three are directly done using built-in functions of the library. Step four needs a particular treatment that we propose as an extension of the original method for large corpuses, which is detailed in the following.

\paragraph{Bootstrap on random subcorpuses for relevance estimation}

Once multi-stems have been extracted, one scores them by \emph{unithood}, defined for the multi-stem $i$ by $u_i = f_i\cdot \log{(1 + l_i)}$ where $f_i$ is the number of apparitions of the multi-stem over the whole corpus and $l_i$ its length in words. Let $K_w$ the maximal number of relevant keywords per patent. If $N$ is the total number of relevant keywords extracted 
The heuristic described in~\cite{chavalarias2013phylomemetic} proposes a first filtration of $4\cdot N$ keywords on the whole corpus, and then a filtration on a secondary score called \emph{termhood}, computed as a chi-squared score on the distribution of the stem, compared to an uniform distribution within the whole corpus. More precisely, one computes the co-occurence matrix $(M_{ij})$, defined as the number of patents where stems $i$ and $j$ appear together, what allows to define the termhood score as
\[
t_i = \sum_{j\neq i}\frac{\left( M_{ij} - \sum_{k}M_{ik} \sum_{k} M_{jk}\right)^2}{\sum_{k}M_{ik} \sum_{k} M_{jk}}
\]




\paragraph{Possible Features}






\paragraph{Multilayer Network Analysis}
Check out the method proposed in~\cite{iacovacci2015mesoscopic}. $\rightarrow$ Interesting for some kind of ``between-layers correlation'' ?








%%%%%%%%%%%%%%%%%%%%
\section{Results}
%%%%%%%%%%%%%%%%%%%%









%%%%%%%%%%%%%%%%%%%%
%% Biblio
%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{apalike}
\bibliography{../../Biblio/patents}


\end{document}


