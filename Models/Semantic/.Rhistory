}
g=ggplot(data.frame(pops,times))
g+geom_density(aes(x=pops,colour=as.character(times)),show.legend=FALSE)+xlim(c(-2,20))
n=100000
#p0 = rlnorm(n)
p0=runif(n)
growthRates<-function(){rnorm(n,mean=1.1,sd = 0.05)}
nextDistrib <- function(p){sample(growthRates()*p,n)}
pops=p0;times=rep(0,n)
p=p0
for(t in 1:100){
p=nextDistrib(p)
pops=append(pops,p);times=append(times,rep(t,n))
show(mean(p))
}
g=ggplot(data.frame(pops,times))
g+geom_density(aes(x=pops,colour=as.character(times)),show.legend=FALSE)+xlim(c(-2,20))
hist(p,plot=FALSE)
p0 = rlnorm(n)
#p0=runif(n)
growthRates<-function(){rnorm(n,mean=1,sd = 0.05)}
nextDistrib <- function(p){sample(growthRates()*p,n)}
pops=p0;times=rep(0,n)
p=p0
for(t in 1:100){
p=nextDistrib(p)
pops=append(pops,p);times=append(times,rep(t,n))
show(mean(p))
}
p0=runif(n)
growthRates<-function(){rnorm(n,mean=1,sd = 0.05)}
nextDistrib <- function(p){sample(growthRates()*p,n)}
pops=p0;times=rep(0,n)
p=p0
for(t in 1:100){
p=nextDistrib(p)
pops=append(pops,p);times=append(times,rep(t,n))
show(mean(p))
}
gc()
gc()
spatializedExpMixtureDensity <- function(gridSize,N,alpha,proba=TRUE,rmin=0,rmax=0,Pmax=1,tolThreshold=0,kernel_type="poisson"){
if(rmin==0){rmin = gridSize/N}
if(rmax==0){rmax = gridSize/N}
# patches of the grid are 1 unit size (in r_min/max units)
grid = matrix(0,gridSize,gridSize)
# matrix of coordinates
coords = matrix(c(c(matrix(rep(1:gridSize,gridSize),nrow=gridSize)),c(matrix(rep(1:gridSize,gridSize),nrow=gridSize,byrow=TRUE))),nrow=gridSize^2)
# first draw param distribs ? not needed
# for exp distribs, P_i = 2pi*d_i*r_i^2
#  -> take P from deterministic distrib ; draw r.
for(i in 1:N){
#show(i)
pop_i = Pmax*i^{-alpha}
r_i = runif(1,min=rmin,max=rmax)
d_i = pop_i / (2*pi*(r_i^2))
# find origin of that kernel
#  -> one of points such that : d(bord) > rcut and \forall \vec{x}\in D(rcut),d(\vec{x})<tolThr.
#pot = which(!pseudoClosing(grid>tolThreshold,r_i),arr.ind=TRUE)
#show(length(pot))
#if(length(pot)==0){
#  # Take a point with minimal density ?
#  pot = which(grid==min(grid),arr.ind=TRUE)
#}
# simplify : take deterministiquely (almost, after two exps only two points possible)
# BUT not close to border
#rbord = 2*rmax*log(Pmax/tolThreshold)
rbord = 2*rmax
# random center
if(max(grid)==0){
# random if no center yet
center = matrix(runif(2,min=rbord+1,max=gridSize-rbord),nrow=1)
}
else {
# else find min pop area not too close to border
pot = which(grid==min(grid[(rbord+1):(gridSize-rbord),(rbord+1):(gridSize-rbord)]),arr.ind=TRUE)
row = sample(nrow(pot),1)
center = matrix(pot[row,],nrow=1)
}
# add kernel : use kernlab laplace kernel or other
if(kernel_type=="poisson"){ker=laplacedot(sigma=1/r_i)}
if(kernel_type=="gaussian"){ker=rbfdot(sigma=1/(2*r_i^2))}
#if(kernel_type="quadratic"){ker=} # is quad kernel available ?
grid = grid + (d_i * matrix(kernelMatrix(kernel=laplacedot(sigma=1/r_i),x=coords,y=center),nrow=gridSize))
}
if(proba==TRUE){grid = grid / sum(grid)}
return(grid)
}
test = spatializedExpMixtureDensity(100,2,0.7)
library(kernlab)
test = spatializedExpMixtureDensity(100,10,0.7)
#test = spatializedExpMixtureDensity(100,3,0.7)
test = spatializedExpMixtureDensity(100,3,0.7)
test = spatializedExpMixtureDensity(100,4,0.7)
test = spatializedExpMixtureDensity(100,5,0.7)
spatializedExpMixtureDensity <- function(gridSize,N,alpha,proba=TRUE,rmin=0,rmax=0,Pmax=1,tolThreshold=0,kernel_type="poisson"){
if(rmin==0){rmin = gridSize/N}
if(rmax==0){rmax = gridSize/N}
# patches of the grid are 1 unit size (in r_min/max units)
grid = matrix(0,gridSize,gridSize)
# matrix of coordinates
coords = matrix(c(c(matrix(rep(1:gridSize,gridSize),nrow=gridSize)),c(matrix(rep(1:gridSize,gridSize),nrow=gridSize,byrow=TRUE))),nrow=gridSize^2)
# first draw param distribs ? not needed
# for exp distribs, P_i = 2pi*d_i*r_i^2
#  -> take P from deterministic distrib ; draw r.
for(i in 1:N){
show(i)
pop_i = Pmax*i^{-alpha}
r_i = runif(1,min=rmin,max=rmax)
d_i = pop_i / (2*pi*(r_i^2))
# find origin of that kernel
#  -> one of points such that : d(bord) > rcut and \forall \vec{x}\in D(rcut),d(\vec{x})<tolThr.
#pot = which(!pseudoClosing(grid>tolThreshold,r_i),arr.ind=TRUE)
#show(length(pot))
#if(length(pot)==0){
#  # Take a point with minimal density ?
#  pot = which(grid==min(grid),arr.ind=TRUE)
#}
# simplify : take deterministiquely (almost, after two exps only two points possible)
# BUT not close to border
#rbord = 2*rmax*log(Pmax/tolThreshold)
rbord = 2*rmax
# random center
if(max(grid)==0){
# random if no center yet
center = matrix(runif(2,min=rbord+1,max=gridSize-rbord),nrow=1)
}
else {
# else find min pop area not too close to border
pot = which(grid==min(grid[(rbord+1):(gridSize-rbord),(rbord+1):(gridSize-rbord)]),arr.ind=TRUE)
row = sample(nrow(pot),1)
center = matrix(pot[row,],nrow=1)
}
# add kernel : use kernlab laplace kernel or other
if(kernel_type=="poisson"){ker=laplacedot(sigma=1/r_i)}
if(kernel_type=="gaussian"){ker=rbfdot(sigma=1/(2*r_i^2))}
#if(kernel_type="quadratic"){ker=} # is quad kernel available ?
grid = grid + (d_i * matrix(kernelMatrix(kernel=laplacedot(sigma=1/r_i),x=coords,y=center),nrow=gridSize))
}
if(proba==TRUE){grid = grid / sum(grid)}
return(grid)
}
test = spatializedExpMixtureDensity(100,5,0.7)
test = spatializedExpMixtureDensity(100,4,0.7)
test = spatializedExpMixtureDensity(100,5,0.7)
persp3D(z=test)
library(plot3D)
persp3D(z=test)
test = spatializedExpMixtureDensity(100,10,0.7)
test = spatializedExpMixtureDensity(100,20,0.7)
persp3D(z=test)
library(igraph)
hep(simplify())
help(simplify)
localGraph=list()
localGraph$gg
is.null(localGraph$gg)
48*400
help(try)
#'   ! assuming q > 0
quantilesToHist<-function(q){
mids=c();density=c()
a = 1/length(q)
qq=c(0,q)
for(i in 1:length(q)){mids = append(mids,(qq[i]+qq[i+1])/2);density=append(density,a/(qq[i+1]-qq[i]))}
res=list()
res$mids=mids;res$density=density
return(res)
}
quantilesToHist(1:10)
help("try")
tryCatch({x+1})
tryCatch({x+1},error=function(e){show("tos")})
tryCatch({x+1},error=function(e){return("tos")})
tryCatch({x+1},error=function(e){return(2)})
tryCatch({x+1},error=function(e){res=2})
res
library(raster)
help("focal")
strsplit("1998;2008;2554")
strsplit("1998;2008;2554",";")
strsplit("1998;2008;2554",";")[[1]]
kwNum = 100000
yearRange=c(1976,1977,1978,1979,1980)
year = paste0(as.character(yearRange[1]),"-",as.character(yearRange[length(yearRange)]))
paste0('relevant.relevant_',year,'_full_',kwNum)
paste0('relevant.relevant_',year,'_full_',kwNum)
5*6*3*10*5
5*6*3*10*5*3
5*6*3*10*5*3*20
5*6*3*10*5*7*20
getwd()
pop = load('Data/GibratSim/countriesPop.RData')
pop
CHina
China
library(dplyr)
as.tbl(China)
China[9000:9100,]
as.tbl(China_Historic)
mmax(China$`2010`)
max(China$`2010`)
hist(China$`2010`,breaks=500)
library(ggplot2)
g=ggplot(China)
d=data.frame()
for(j in 5:8){
d=rbind(d,cbind(sort(China[,j],decreasing = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
sort(China[,j],decreasing = TRUE)
1:nrow(China)
d=data.frame()
for(j in 5:8){
d=rbind(d,data.frame(sort(China[,j],decreasing = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
nrow(China)
China[,j]
d=data.frame()
for(j in 5:8){
d=rbind(d,data.frame(sort(China[,j],decreasing = TRUE,na.last = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
colnames(d)<-c("size","rank","year")
colnames(d)
dim(d)
g=ggplot(d)
g+geom_point(aes(x=rnake,y=size,colour=year))
g+geom_point(aes(x=rank,y=size,colour=year))
g+geom_point(aes(x=log(rank),y=log(size),colour=year))
help("geom_bar")
192000 * 109 / 200
192000 * 109 / 200 / 3600
192000 * 109 / 200 / 3600 / 10
192000 * 109 / 200 / 3600 / 20
14/1.38
50*49/2
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv')
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv',sep=";")
d
head(d)
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv',sep=";",header=FALSE)
head(d)
head(d,n = 100)
which(d[,2]==0)
which(d[,2]==2)
unique(d[,2])
help(apply)
help(Matrix)
library(Matrix)
help("Matrix")
library(raster)
help("focal")
NCmisc::estimate.memory()
install.packages("NCmisc")
NCmisc::estimate.memory()
library(NCmisc)
help("estimate.memory")
year=1980;yearrange=paste0((year-windowSize+1),"-",year)
library(Matrix)
library(ggplot2)
library(dplyr)
library(reshape2)
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Models/Semantic'))
wyears = 1980:2012
windowSize=5
#source('semanalfun.R')
year=1980;yearrange=paste0((year-windowSize+1),"-",year)
load(file=paste0('probas_processed/processed_count_',yearrange,'.RData'))
load(file=paste0('probas/processed_counts_',yearrange,'.RData'))
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
dim(semprobas)
year=1980;yearrange=paste0((year-windowSize+1),"-",year)
kwex <- as.tbl(read.csv(paste0("keywords/keywords_",yearrange,"_kwLimit",kwLimit,"_dispth0.06_ethunit4.5e-05.csv"),sep=";",header=FALSE))
kwLimit="100
kwLimit="100000"
kwLimit="100000"
year=1980;yearrange=paste0((year-windowSize+1),"-",year)
kwex <- as.tbl(read.csv(paste0("keywords/keywords_",yearrange,"_kwLimit",kwLimit,"_dispth0.06_ethunit4.5e-05.csv"),sep=";",header=FALSE))
kwex
kwex %>% group_by(V2)
kwex %>% group_by(V2) %>% summarise(count=n())
kwex <- as.tbl(read.csv(paste0("keywords/keywords-counts_",yearrange,"_kwLimit",kwLimit,"_dispth0.06_ethunit4.5e-05.csv"),sep=";",header=FALSE))
kwex <- as.tbl(read.csv(paste0("probas_count_extended/keywords-count-extended_",yearrange,"_kwLimit",kwLimit,"_dispth0.06_ethunit4.5e-05.csv"),sep=";",header=FALSE))
kwex
kwex %>% group_by(V2) %>% summarise(count=n())
sizes = kwex %>% group_by(V2) %>% summarise(count=n())
sizes$count
sizes$count[sizes$count<4]
sum(sizes$count[sizes$count<4])
sum(sizes$count[sizes$count<4])/sum(sizes$count)
year=2004;yearrange=paste0((year-windowSize+1),"-",year)
kwex <- as.tbl(read.csv(paste0("probas_count_extended/keywords-count-extended_",yearrange,"_kwLimit",kwLimit,"_dispth0.06_ethunit4.5e-05.csv"),sep=";",header=FALSE))
sizes = kwex %>% group_by(V2) %>% summarise(count=n())
sum(sizes$count[sizes$count<4])/sum(sizes$count)
sizes=c();nsizes=c();years=c();type=c();ranks=c();sortedsizes=c();sortednsizes=c()
for(year in wyears){
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'));show(year)
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
techsizes=colSums(technoprobas);semsizes=colSums(semprobas)
techsizes=techsizes[techsizes>0];semsizes=semsizes[semsizes>0]
sizes=append(sizes,sort(techsizes,decreasing=TRUE)/nrow(technoprobas));years=append(years,rep(year,length(techsizes)));ranks=append(ranks,1:length(techsizes));type=append(type,rep("techno",length(techsizes)))
sizes=append(sizes,sort(semsizes,decreasing=TRUE)/nrow(semprobas));years=append(years,rep(year,length(semsizes)));ranks=append(ranks,1:length(semsizes));type=append(type,rep("semantic",length(semsizes)))
#nsizes=append(nsizes,techsizes/nrow(technoprobas));;type=append(type,rep("techno",length(techsizes)));
#ranks=append(ranks,1:length(techsizes));sortedsizes=append(sortedsizes,sort(techsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(techsizes/nrow(technoprobas),decreasing = TRUE))
#sizes=append(sizes,semsizes);nsizes=append(nsizes,semsizes/nrow(semprobas));years=append(years,rep(year,length(semsizes)));type=append(type,rep("semantic",length(semsizes)))
#ranks=append(ranks,1:length(semsizes));sortedsizes=append(sortedsizes,sort(semsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(semsizes/nrow(semprobas),decreasing = TRUE))
}
sizes=c();nsizes=c();years=c();type=c();ranks=c();sortedsizes=c();sortednsizes=c()
for(year in wyears){
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'));show(year)
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
techsizes=colSums(technoprobas);semsizes=colSums(semprobas)
techsizes=techsizes[techsizes>0];semsizes=semsizes[semsizes>0]
sizes=append(sizes,sort(techsizes,decreasing=TRUE)/nrow(technoprobas));years=append(years,rep(year,length(techsizes)));ranks=append(ranks,1:length(techsizes));
type=append(type,rep("technological classes",length(techsizes)))
sizes=append(sizes,sort(semsizes,decreasing=TRUE)/nrow(semprobas));years=append(years,rep(year,length(semsizes)));ranks=append(ranks,1:length(semsizes));
type=append(type,rep("semantic classes",length(semsizes)))
#nsizes=append(nsizes,techsizes/nrow(technoprobas));;type=append(type,rep("techno",length(techsizes)));
#ranks=append(ranks,1:length(techsizes));sortedsizes=append(sortedsizes,sort(techsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(techsizes/nrow(technoprobas),decreasing = TRUE))
#sizes=append(sizes,semsizes);nsizes=append(nsizes,semsizes/nrow(semprobas));years=append(years,rep(year,length(semsizes)));type=append(type,rep("semantic",length(semsizes)))
#ranks=append(ranks,1:length(semsizes));sortedsizes=append(sortedsizes,sort(semsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(semsizes/nrow(semprobas),decreasing = TRUE))
}
df=data.frame(size=sizes,nsize=nsizes,sortedsize=sortedsizes,sortednsize=sortednsizes,years=as.character(years),type=type)
g=ggplot(df,aes(x=sizes,color=years))
g+geom_density()+scale_x_log10()+facet_wrap(~type)
g=ggplot(df,aes(x=ranks,y=sortedsizes,colour=years,group=years))
g+geom_point()+scale_x_log10()+scale_y_log10()+facet_wrap(~type)
g=ggplot(data.frame(size=sizes,year=as.character(years),rank=ranks,type=type))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("normalized size")
sizes=c();nsizes=c();years=c();type=c();ranks=c();sortedsizes=c();sortednsizes=c()
for(year in wyears){
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'));show(year)
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
techsizes=colSums(technoprobas);semsizes=colSums(semprobas)
techsizes=techsizes[techsizes>0];semsizes=semsizes[semsizes>0]
sizes=append(sizes,sort(techsizes,decreasing=TRUE));
years=append(years,rep(year,length(techsizes)));ranks=append(ranks,1:length(techsizes));
type=append(type,rep("technological classes",length(techsizes)))
sizes=append(sizes,sort(semsizes,decreasing=TRUE));
years=append(years,rep(year,length(semsizes)));ranks=append(ranks,1:length(semsizes));
type=append(type,rep("semantic classes",length(semsizes)))
#nsizes=append(nsizes,techsizes/nrow(technoprobas));;type=append(type,rep("techno",length(techsizes)));
#ranks=append(ranks,1:length(techsizes));sortedsizes=append(sortedsizes,sort(techsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(techsizes/nrow(technoprobas),decreasing = TRUE))
#sizes=append(sizes,semsizes);nsizes=append(nsizes,semsizes/nrow(semprobas));years=append(years,rep(year,length(semsizes)));type=append(type,rep("semantic",length(semsizes)))
#ranks=append(ranks,1:length(semsizes));sortedsizes=append(sortedsizes,sort(semsizes,decreasing = TRUE));sortednsizes=append(sortednsizes,sort(semsizes/nrow(semprobas),decreasing = TRUE))
}
g=ggplot(data.frame(size=sizes,year=as.character(years),rank=ranks,type=type))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("normalized size")
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("size")
ggThemeAssist:::ggThemeAssistAddin()
g=ggplot(data.frame(size=sizes,year=as.character(years),rank=ranks,type=type))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+
scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("size") + theme(axis.title = element_text(size = 25),
axis.text.x = element_text(size = 20),
axis.text.y = element_text(size = 20))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+
scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("size") + theme(axis.title = element_text(size = 16),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12))
g=ggplot(data.frame(size=sizes,year=as.character(years),rank=ranks,type=type))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+
scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("size") + theme(axis.title = element_text(size = 18),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))
g+geom_line(aes(x=rank,y=size,colour=year,group=year))+
scale_x_log10()+scale_y_log10()+facet_wrap(~type,scales="fixed")+ylab("size") + theme(axis.title = element_text(size = 22),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))
origs=c();cyears=c();types=c();
for(year in wyears){
show(year)
#load(paste0('probas_processed/processed_',year,'.RData'))
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'))
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
origs = append(origs,1 - rowSums(semprobas^2));types=append(types,rep("semantic",nrow(semprobas)))
origs = append(origs,1 - rowSums(technoprobas^2));types=append(types,rep("techno",nrow(technoprobas)))
cyears=append(cyears,rep(year,nrow(semprobas)+nrow(technoprobas)))
rm(semprobas,technoprobas);gc()
}
save(origs,cyears,types,file='res/patentlevel_orig.RData')
origs=c();cyears=c();types=c();
for(year in wyears){
show(year)
#load(paste0('probas_processed/processed_',year,'.RData'))
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'))
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
origs = append(origs,1 - rowSums(semprobas^2));types=append(types,rep("semantic classification",nrow(semprobas)))
origs = append(origs,1 - rowSums(technoprobas^2));types=append(types,rep("technological classification",nrow(technoprobas)))
cyears=append(cyears,rep(year,nrow(semprobas)+nrow(technoprobas)))
rm(semprobas,technoprobas);gc()
}
save(origs,cyears,types,file='res/patentlevel_orig.RData')
library(Matrix)
library(ggplot2)
library(dplyr)
library(reshape2)
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Models/Semantic'))
wyears = 1980:2012
windowSize=5
kwLimit="100000"
#source('semanalfun.R')
load('res/patentlevel_origs.RData')
load('res/patentlevel_orig.RData')
length(which(origs<1))/length(origs)
inds=origs<1
df = data.frame(originality=origs[inds],year=as.character(cyears[inds]),type=types[inds])
rm(origs,cyears,types);gc()
g=ggplot(df[df$originality>0,])
g+geom_density(aes(x=originality,colour=year))+facet_wrap(~type) +
+xlab("patent diversity")
theme(axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
rm(g);gc()
g=ggplot(df[df$originality>0,])
g+geom_density(aes(x=originality,colour=year))+facet_wrap(~type) +
xlab("patent diversity")+
theme(axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
rm(g);gc()
g=ggplot(df)#[df$originality>0,])
g+geom_density(aes(x=originality,colour=year))+facet_wrap(~type) +
xlab("patent diversity")+
theme(axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
rm(g);gc()
byyearorigs = as.tbl(df[df$originality>0,]) %>% group_by(year,type) %>% summarize(meanorig=mean(originality),count=n())
gsum=ggplot(byyearorigs,aes(x=year,y=meanorig,colour=type,group=type))
labs=rep("",length(wyears));labs[seq(from=1,to=length(labs),by=3)]=as.character(wyears[seq(from=1,to=length(labs),by=3)])
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y",)+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity")
theme(axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
ggThemeAssist:::ggThemeAssistAddin()
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y",)+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity") +
theme(legend.position = "none",axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
labs=rep("",length(wyears));labs[seq(from=1,to=length(labs),by=4)]=as.character(wyears[seq(from=1,to=length(labs),by=3)])
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y",)+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity") +
theme(legend.position = "none",axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y")+
#scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity")
ggThemeAssist:::ggThemeAssistAddin()
labs=rep("",length(wyears));labs[seq(from=1,to=length(labs),by=4)]=as.character(wyears[seq(from=1,to=length(labs),by=4)])
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y")+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity") +
theme(legend.position = "none",axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
labs=rep("",length(wyears));labs[seq(from=1,to=length(labs),by=5)]=as.character(wyears[seq(from=1,to=length(labs),by=5)])
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y")+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity") +
theme(legend.position = "none",axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
byyearorigs = as.tbl(df#[df$originality>0,]
) %>% group_by(year,type) %>% summarize(meanorig=mean(originality),count=n())
gsum=ggplot(byyearorigs,aes(x=year,y=meanorig,colour=type,group=type))
labs=rep("",length(wyears));labs[seq(from=1,to=length(labs),by=5)]=as.character(wyears[seq(from=1,to=length(labs),by=5)])
gsum+geom_point()+geom_line()+facet_wrap(~type,scales ="free_y")+
scale_x_discrete(breaks=as.character(wyears),labels=labs)+
xlab("year")+ylab("mean patent diversity") +
theme(legend.position = "none",axis.title = element_text(size = 22), axis.text.x = element_text(size = 15),  axis.text.y = element_text(size = 15))
load('res/inter_overlaps.RData')
overlaps=unlist(lapply(res,function(l){l$overlap}))
cyears=unlist(lapply(res,function(l){l$year}))
overlaps
inds=overlaps>0
g=ggplot(data.frame(overlaps=overlaps[inds],cyears=as.character(cyears[inds])),aes(x=cyears,y=overlaps))
g+geom_point(pch='.')+scale_y_log10()+stat_smooth()
overlaps = c();years=c();measures=c();types=c();filters=c();nullovs=c();classnum=c();pcount=c();gc()
ovsize=c()
for(year in wyears){
#load(paste0('probas_processed/processed_',(year-windowSize+1),"-",year,'.RData'));show(year)
load(paste0('probas/processed_counts_',(year-windowSize+1),"-",year,'.RData'));show(year)
technoprobas=currentprobas$technoprobas;semprobas=currentprobas$semprobas;rm(currentprobas);gc()
#techov=t(technoprobas)%*%technoprobas;
#diag(techov)<-0
#semov=t(semprobas)%*%semprobas;
#diag(semov)<-0
interov=t(technoprobas)%*%semprobas
#nullovs=append(nullovs,length(which(techov==0)));nullovs=append(nullovs,length(which(semov==0)))
#ovsize=append(ovsize,c(sum(techov),sum(semov)))
#types=append(types,c("techno","semantic"));years=append(years,c(year,year))
#classnum=append(classnum,ncol(techov));classnum=append(classnum,ncol(semov))
#pcount=append(pcount,c(nrow(semprobas),nrow(semprobas)))
# NON NORMALIZED
#overlaps=append(overlaps,as.numeric(interov));n=length(as.numeric(interov));years=append(years,rep(year,n));types=append(types,rep("techno",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(techov));n=length(as.numeric(techov));years=append(years,rep(year,n));types=append(types,rep("techno",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(semov));n=length(as.numeric(semov));years=append(years,rep(year,n));types=append(types,rep("semantic",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("all",n))
#inds=which(techov>0);overlaps=append(overlaps,techov[inds]);n=length(inds);years=append(years,rep(year,n));types=append(types,rep("techno",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("positive",n))
#inds=which(semov>0);overlaps=append(overlaps,semov[inds]);n=length(inds);years=append(years,rep(year,n));types=append(types,rep("semantic",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("positive",n))
# # NORMALIZED PATENT COUNT
#overlaps=append(overlaps,as.numeric(interov)/nrow(technoprobas));n=length(as.numeric(interov));years=append(years,rep(year,n));types=append(types,rep("inter",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(techov)/nrow(technoprobas));n=length(as.numeric(techov));years=append(years,rep(year,n));types=append(types,rep("techno",n));#measures=append(measures,rep("norm-patents",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(semov)/nrow(semprobas));n=length(as.numeric(semov));years=append(years,rep(year,n));types=append(types,rep("semantic",n));#measures=append(measures,rep("norm-patents",n));filters=append(filters,rep("all",n))
#inds=which(techov>0);overlaps=append(overlaps,techov[inds]/nrow(technoprobas));n=length(inds);years=append(years,rep(year,n));types=append(types,rep("techno",n));#measures=append(measures,rep("norm-patents",n));filters=append(filters,rep("positive",n))
#inds=which(semov>0);overlaps=append(overlaps,semov[inds]/nrow(semprobas));n=length(inds);years=append(years,rep(year,n));types=append(types,rep("semantic",n));#measures=append(measures,rep("norm-patents",n));filters=append(filters,rep("positive",n))
# # RELATIVE OVERLAP
#technorm=Matrix(1,nrow(techov),ncol(techov))%*%Diagonal(x=colSums(technoprobas));
#semnorm=Matrix(1,nrow(semov),ncol(semov))%*%Diagonal(x=colSums(semprobas));
internorm=2*(Diagonal(x=1/colSums(technoprobas))%*%Matrix(1,ncol(technoprobas),ncol(semprobas)))+(Matrix(1,ncol(technoprobas),ncol(semprobas))%*%Diagonal(x=1/colSums(semprobas)))
interov=interov*internorm
#techov=techov*2/(technorm+t(technorm))
#semov=semov*2/(semnorm+t(semnorm))
overlaps=append(overlaps,as.numeric(interov));n=length(as.numeric(interov));years=append(years,rep(year,n));types=append(types,rep("techno",n))#;measures=append(measures,rep("real",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(techov));n=length(as.numeric(techov));years=append(years,rep(year,n));types=append(types,rep("techno",n));#measures=append(measures,rep("relative",n));filters=append(filters,rep("all",n))
#overlaps=append(overlaps,as.numeric(semov));n=length(as.numeric(semov));years=append(years,rep(year,n));types=append(types,rep("semantic",n));#measures=append(measures,rep("relative",n));filters=append(filters,rep("all",n))
##inds=which(techov>0);overlaps=append(overlaps,techov[inds]/nrow(technoprobas));n=length(inds);years=append(years,rep(year,n));types=append(types,rep("techno",n));#measures=append(measures,rep("relative",n));filters=append(filters,rep("positive",n))
##inds=which(semov>0);overlaps=append(overlaps,semov[inds]/nrow(semprobas));n=length(inds);years=append(years,rep(year,n));types=append(types,rep("semantic",n));#measures=append(measures,rep("relative",n));filters=append(filters,rep("positive",n))
rm(techov,semov,technorm,semnorm,technoprobas,semprobas);gc()
}
warnings()
max(overlaps)
interov
