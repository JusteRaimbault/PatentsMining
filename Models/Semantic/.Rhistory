for(i in 1:nrow(overlap)){
show(i)
links = links + (overlap[i,i]^2)
if(i<nrow(overlap)){
for(j in (i+1):ncol(overlap)){
overlap[j,j] = overlap[j,j] - overlap[i,j]
}
}
}
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining'))
Sys.getenv('CS_HOME')
pr <- prcomp(cormat[1,8:17])
setwd(paste0(Sys.getenv('CN_HOME'),'/Results/Synthetic/Network'))
setwd(paste0(Sys.getenv('CN_HOME'),'/Results/Synthetic/Network'))
getwd()
install.packages('cartography')
install.packages('cartography',source=T)
help(install.packages)
install.packages('cartography',type='source')
library(cartography)
help(cartography)
citation(package="cartography")
resdir='20160106_LHSDensityNW/data/'
cartography: vignette(topic = "cartography")
cartography:vignette(topic = "cartography")
vignette(topic = "cartography")
data("nuts2006")
EuropeStamen <- getTiles(spdf = nuts0.spdf, type = "stamen-watercolor")
install.packages('OpenStreetMap')
EuropeStamen <- getTiles(spdf = nuts0.spdf, type = "stamen-watercolor")
tilesLayer(EuropeStamen)
plot(nuts0.spdf, add=TRUE)
mtext(text = "Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under CC BY SA.",
side = 1, adj = 0, cex = 0.7, font = 3)
install.packages('shiny')
shiny::runApp('~/Documents/ComplexSystems/Misc/Anna/063-superzip-example')
library(maps)
library(mapdata)
library(rworldmap)
load("~/Documents/ComplexSystems/CyberGeo/cybergeo20/HyperNetwork/Models/Analysis/20160217.RData")
library(dplyr)
library(igraph)
com
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
thematics = list()
for(i in 1:length(V(gg))){
thematics[[V(g)$name[i]]]=com$membership[i]
}
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 100  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
com = cluster_louvain(gg)
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 100  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
kmin = 0
kmax = 1050  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
kmax = 1020  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
for(i in unique(com$membership)){show(i);show(V(g)$name[which(com$membership==i)])}
for(i in unique(com$membership)){show(i);show(V(gg)$name[which(com$membership==i)])}
kmax = 1000  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
for(i in unique(com$membership)){show(i);show(V(gg)$name[which(com$membership==i)])}
thematics = list()
for(i in 1:length(V(gg))){
thematics[[V(g)$name[i]]]=com$membership[i]
}
# compute proba matrix
them_probas = matrix(0,length(names(keyword_dico)),length(unique(com$membership)))
for(i in 1:length(names(keyword_dico))){
if(i%%100==0){show(i)}
kwcount=0
for(kw in keyword_dico[[names(keyword_dico)[i]]]){if(kw %in% names(thematics)){
j=thematics[[kw]]
them_probas[i,j]=them_probas[i,j]+1;kwcount=kwcount+1
}}
if(kwcount>0){them_probas[i,]=them_probas[i,]/kwcount}
}
# number of articles with originality
#length(which(rowSums(them_probas)>0))
originalities=apply(them_probas,MARGIN = 1,FUN = function(r){if(sum(r)==0){return(0)}else{return(1 - sum(r^2))}})
cybindexes = c();cybresnames = c();iscyb=rep(FALSE,length(originalities))
for(cyb in cybnames){
indexes = which(names(keyword_dico)==cyb);
if(length(indexes)>0){
cybindexes=append(cybindexes,indexes[1]);
cybresnames=append(cybresnames,cyb)
iscyb[indexes[1]]=TRUE
}}
ggplot(data.frame(orig=originalities,cyb=iscyb), aes(x=orig, fill=cyb)) + geom_density(alpha=.3)
library(ggplot2)
ggplot(data.frame(orig=originalities,cyb=iscyb), aes(x=orig, fill=cyb)) + geom_density(alpha=.3)
length(which(iscyb))
sdat=as.tbl(dat)%>%group_by(iscyb)%>%summarise(mean=mean(orig))
dat=data.frame(orig=originalities,cyb=iscyb)
sdat=as.tbl(dat)%>%group_by(iscyb)%>%summarise(mean=mean(orig))
sdat=as.tbl(dat)%>%group_by(cyb)%>%summarise(mean=mean(orig))
length(which(iscyb))
dat=data.frame(orig=originalities,cyb=iscyb)
sdat=as.tbl(dat)%>%group_by(cyb)%>%summarise(mean=mean(orig))
library(ggplot2)
g=ggplot(dat, aes(x=orig, fill=cyb))
g+ geom_density(alpha=.3)+geom_vline(data=sdat, aes(xintercept=mean,  colour=cyb),
linetype="dashed", size=1)
sdat
dat
as.tbl(dat)%>%group_by(cyb)
g=ggplot(dat, aes(x=orig, fill=cyb))
g+ geom_density(alpha=.3)
cybprobas = them_probas[cybindexes,]
cybcumprobas = colSums(cybprobas)/length(which(rowSums(cybprobas)>0))
1 - sum(cybcumprobas^2)
sdat
Nb = 10000
nulljournalorigs=c()
for(i in 1:Nb){
probas = them_probas[sample.int(nrow(them_probas), size = length(cybindexes), replace = FALSE),]
cumprobas = colSums(probas)/length(which(rowSums(probas)>0))
nulljournalorigs=append(nulljournalorigs,1 - sum(cumprobas^2))
}
hist(nulljournalorigs,breaks=1000)
mean(nulljournalorigs)
head(them_probas)
i=1
neighbors(gcitation,v=cybnodes[i],mode="in")$name
gcitation
cybnodes
cybnodes=V(gcitation)[V(gcitation)$cyb==1]
cybnodes
neighbors(gcitation,v=cybnodes[i],mode="in")$name
keyword_dico[[neighbors(gcitation,v=cybnodes[i],mode="in")$name]]
cybsecorigin=c()
cybsecorigout=c()
cybsecorigall=c()
for(i in cybindexes){
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="in")$name
probas = rep(0,ncol(them_probas));count=0
for(n in 1:length(neigh)){
inds = which(names(keyword_dico==neigh[n]))
if(length(inds)>0){probas=probas+them_probas[inds[1],];count=count+1}
}
if(count>0){probas=probas/count}
if(sum(probas)>0){cybsecorigin=append(cybsecorigin,1-sum(probas^2))}
}
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="in")$name
## second order originality ?
cybsecorigin=c()
cybsecorigout=c()
cybsecorigall=c()
for(i in 1:length(cybnodes)){
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="in")$name
probas = rep(0,ncol(them_probas));count=0
for(n in 1:length(neigh)){
inds = which(names(keyword_dico==neigh[n]))
if(length(inds)>0){probas=probas+them_probas[inds[1],];count=count+1}
}
if(count>0){probas=probas/count}
if(sum(probas)>0){cybsecorigin=append(cybsecorigin,1-sum(probas^2))}
}
cybsecorigin=c()
cybsecorigout=c()
cybsecorigall=c()
for(i in 1:length(cybnodes)){
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="in")$name
show(neigh)
probas = rep(0,ncol(them_probas));count=0
for(n in 1:length(neigh)){
inds = which(names(keyword_dico==neigh[n]))
if(length(inds)>0){probas=probas+them_probas[inds[1],];count=count+1}
}
if(count>0){probas=probas/count}
if(sum(probas)>0){cybsecorigin=append(cybsecorigin,1-sum(probas^2))}
}
cybsecorigin=c()
cybsecorigout=c()
cybsecorigall=c()
for(i in 1:length(cybnodes)){
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="in")$name
show(neigh)
probas = rep(0,ncol(them_probas));count=0
for(n in 1:length(neigh)){
inds = which(names(keyword_dico)==neigh[n])
if(length(inds)>0){probas=probas+them_probas[inds[1],];count=count+1}
}
if(count>0){probas=probas/count}
if(sum(probas)>0){cybsecorigin=append(cybsecorigin,1-sum(probas^2))}
}
cybsecorigout=c()
#cybsecorigall=c()
for(i in 1:length(cybnodes)){
show(i)
neigh = neighbors(gcitation,v=cybnodes[i],mode="out")$name
show(neigh)
probas = rep(0,ncol(them_probas));count=0
for(n in 1:length(neigh)){
inds = which(names(keyword_dico)==neigh[n])
if(length(inds)>0){probas=probas+them_probas[inds[1],];count=count+1}
}
if(count>0){probas=probas/count}
if(sum(probas)>0){cybsecorigout=append(cybsecorigout,1-sum(probas^2))}
}
dat = data.frame(orig=c(cybsecorigin,cybsecorigout),type=c(rep("in",length(cybsecorigin),rep("out",length(cybsecorigout)))
)
)
c(cybsecorigin,cybsecorigout)
dat = data.frame(orig=c(cybsecorigin,cybsecorigout),type=c(rep("in",length(cybsecorigin)),rep("out",length(cybsecorigout)))
)
dat
g=ggplot(dat, aes(x=orig, fill=type)) + geom_density(alpha=.3)
ggplot(dat, aes(x=orig, fill=type)) + geom_density(alpha=.3)
sdat=as.tbl(dat)%>%group_by(type)%>%summarise(mean=mean(orig))
ggplot(dat, aes(x=orig, fill=type)) + geom_density(alpha=.3)+geom_vline(data=sdat, aes(xintercept=mean,  colour=cyb),linetype="dashed", size=1)
ggplot(dat, aes(x=orig, fill=type)) + geom_density(alpha=.3)+geom_vline(data=sdat, aes(xintercept=mean,  colour=type),linetype="dashed", size=1)
is.numeric("12")
as.numeric("12")
as.numeric("12mph")
is.numeric(as.numeric("12mph"))
gsub(x = "30 mph"," ","")
s=gsub(x = "30 mph"," ","")
s=gsub(x = s," ","")
s
sr=gsub(x = s," ","")
normalizedSpeed <- function(s){
if(!is.na(as.numeric(s))){return(as.numeric(s))}
sr=gsub(x = s," ","")
if(grepl("mph",sr)){return(as.numeric(gsub(x = sr,"mph",""))*1.609)}
else{return(NA)}
}
normalizedSpeed("30 mph")
normalizedSpeed("30mph")
normalizedSpeed("30")
normalizedSpeed(30)
raw <- raster(paste0(Sys.getenv("CN_HOME"),"/Data/PopulationDensity/raw/density_wgs84.tif"))
library(raster)
raw <- raster(paste0(Sys.getenv("CN_HOME"),"/Data/PopulationDensity/raw/density_wgs84.tif"))
raw
xyFromCell()
xyFromCell
xyFromCell(raw,1230)
library(RPostgreSQL)
library(rgeos)
con = dbConnect(dbDriver("PostgreSQL"), dbname="osm_simpl",user="Juste",host="localhost" )
query = dbSendQuery(con,"SELECT ST_AsText(geography) AS geom FROM links;")
data = fetch(query,n=-1)
geoms = data$geom
roads=list()
for(i in 1:length(geoms)){
r=readWKT(geoms[i])@lines[[1]];r@ID=as.character(i)
roads[[i]]=r
}
splines = SpatialLines(LinesList = roads)
plot(splines)
library(igraph)
help("difference")
real_raw = read.csv(
paste0(Sys.getenv("CN_HOME"),'/Results/Morphology/Density/Numeric/20150806_europe50km_10kmoffset_100x100grid.csv'),
sep=";"
)
real =real_raw[!is.na(real_raw[,3])&!is.na(real_raw[,4])&!is.na(real_raw[,5])&!is.na(real_raw[,6])&!is.na(real_raw[,7])&!is.na(real_raw[,8])&!is.na(real_raw[,9]),]
for(j in 1:ncol(real)){real[,j]=(real[,j]-min(real[,j]))/(max(real[,j])-min(real[,j]))}
library(RColorBrewer)
library(ggplot2)
library(MASS)
source(paste0(Sys.getenv('CN_HOME'),'/Models/Utils/R/plots.R'))
real_raw = read.csv(
paste0(Sys.getenv("CN_HOME"),'/Results/Morphology/Density/Numeric/20150806_europe50km_10kmoffset_100x100grid.csv'),
sep=";"
)
real =real_raw[!is.na(real_raw[,3])&!is.na(real_raw[,4])&!is.na(real_raw[,5])&!is.na(real_raw[,6])&!is.na(real_raw[,7])&!is.na(real_raw[,8])&!is.na(real_raw[,9]),]
real_ind = real[5*(0:(nrow(real)/5))+1,]
names(real)
indic="moran"
p = ggplot(data.frame(x=real$y,y=1-real$x,density_max=real[[indic]]),aes(x=x,y=y,colour=density_max))
p+geom_point()+xlab("")+ylab("")+labs(title=indic)+scale_colour_gradientn(colours=rev(rainbow(5)))+scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)
indic="distance"
p = ggplot(data.frame(x=real$y,y=1-real$x,density_max=real[[indic]]),aes(x=x,y=y,colour=density_max))
p+geom_point()+xlab("")+ylab("")+labs(title=indic)+scale_colour_gradientn(colours=rev(rainbow(5)))+scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)
map<-function(indic){
d=data.frame(x=real$y,y=1-real$x);d[[indic]]=real[[indic]]
p=ggplot(d,aes_string(x="x",y="y",colour=indic))
p+geom_point(shape=".",size=2)+xlab("")+ylab("")+labs(title=indic)+scale_colour_gradientn(colours=rev(rainbow(5)))+scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)
}
# multiplots
indics=c("moran","distance","entropy","slope")
plots=list();k=1
for(indic in indics){
plots[[k]]=map(indic)
k=k+1
}
multiplot(plotlist=plots,cols=2)
map<-function(indic){
d=data.frame(x=real$y,y=1-real$x);d[[indic]]=real[[indic]]
p=ggplot(d,aes_string(x="x",y="y",colour=indic))
p+geom_point(shape=".",size=1)+xlab("")+ylab("")+labs(title=indic)+scale_colour_gradientn(colours=rev(rainbow(5)))+scale_y_continuous(breaks=NULL)+scale_x_continuous(breaks=NULL)
}
# multiplots
indics=c("moran","distance","entropy","slope")
plots=list();k=1
for(indic in indics){
plots[[k]]=map(indic)
k=k+1
}
multiplot(plotlist=plots,cols=2)
names(real)
vars = c(3,4,5,6)
ccoef=c()
for(k in 2:15){
show(k)
clust = kmeans(real[,vars],k,iter.max=30)
#ccoef=append(ccoef,sum(clust$withinss/clust$size)/k)# mean cluster size
ccoef=append(ccoef,clust$tot.withinss/clust$betweenss)# clust coef
plot(real$y,1-real$x,col=clust$cluster,pch='.',cex=3,main=paste0('k=',k),xlab="",ylab="",xaxt='n',yaxt='n')
}
ccoef
vars = c(3,4,5,6)
ccoef=c()
for(k in 2:15){
show(k)
clust = kmeans(real[,vars],k,iter.max=30)
#ccoef=append(ccoef,sum(clust$withinss/clust$size)/k)# mean cluster size
ccoef=append(ccoef,clust$tot.withinss/(clust$betweenss+clust$tot.withinss))# clust coef
plot(real$y,1-real$x,col=clust$cluster,pch='.',cex=3,main=paste0('k=',k),xlab="",ylab="",xaxt='n',yaxt='n')
}
ccoef
vars = c(3,4,5,6)
ccoef=c()
par(mfrow=c(3,3))
for(k in 2:11){
show(k)
clust = kmeans(real[,vars],k,iter.max=30)
#ccoef=append(ccoef,sum(clust$withinss/clust$size)/k)# mean cluster size
withinProp=clust$tot.withinss/(clust$betweenss+clust$tot.withinss)
ccoef=append(ccoef,withinProp)# clust coef
plot(real$y,1-real$x,col=clust$cluster,pch='.',cex=3,main=paste0('k=',k,' ; withinProp=',withinProp),xlab="",ylab="",xaxt='n',yaxt='n')
}
vars = c(3,4,5,6)
ccoef=c()
par(mfrow=c(3,3))
for(k in 3:11){
show(k)
clust = kmeans(real[,vars],k,iter.max=30)
#ccoef=append(ccoef,sum(clust$withinss/clust$size)/k)# mean cluster size
withinProp=clust$tot.withinss/(clust$betweenss+clust$tot.withinss)
ccoef=append(ccoef,withinProp)# clust coef
plot(real$y,1-real$x,col=clust$cluster,pch='.',cex=3,main=paste0('k=',k,' ; withinProp=',withinProp),xlab="",ylab="",xaxt='n',yaxt='n')
}
shiny::runApp('~/Documents/ComplexSystems/CyberGeo/cybergeo20/Cybergeo20')
help("forceNetwork")
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Models/Semantic'))
years = 1976:2012
kmin = 0;freqmin = 50;edge_th = 50;kmaxdec=0.25;freqmaxdec=0.25
sizeTh=10
semprefix = paste0('_full_100000_kmin',kmin,'_kmaxdec',kmaxdec,'_freqmin',freqmin,'_freqmaxdec',freqmaxdec,'_eth',edge_th,'.RData')
technoprefix=paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Data/processed/classes/technoPerYear/technoProbas_')
loadProbas<-function(year){
show(year)
res=list()
load(paste0('probas/relevant_',year,semprefix))
res$semprobas=probas[,3:ncol(probas)]
load(paste0(technoprefix,year,'_sizeTh',sizeTh,'.RData'))
rowstoadd=setdiff(rownames(res$semprobas),rownames(m))
m=rbind(m,matrix(0,length(rowstoadd),ncol(m)));rownames(m)[(nrow(m)-length(rowstoadd)+1):nrow(m)]=rowstoadd
res$technoprobas = m[rownames(res$semprobas),]
return(res)
}
load(paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Data/processed/citation/adjacency.RData'))
load(paste0(Sys.getenv('CS_HOME'),'/PatentsMining/Data/processed/citation/network/adjacency.RData'))
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=res$technoprobas;semprobas=res$semprobas
currentadj = citadjacency[rownames(technoprobas),rownames(technoprobas)]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = currentadj%*%technoprobas
semcit = currentadj%*%semprobas
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
rownames(citadjacency)
intersection(rownames(citadjacency),rownames(technoprobas))
inter(rownames(citadjacency),rownames(technoprobas))
library(dplyr)
intersection(rownames(citadjacency),rownames(technoprobas))
help(setdiff)
intersect(rownames(citadjacency),rownames(technoprobas))
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=res$technoprobas;semprobas=res$semprobas
currentnames=intersect(rownames(technoprobas),rownames(citadjacency))
currentadj = citadjacency[currentnames,currentnames]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = currentadj%*%technoprobas
semcit = currentadj%*%semprobas
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=res$technoprobas;semprobas=res$semprobas
currentnames=intersect(rownames(technoprobas),rownames(citadjacency))
currentadj = citadjacency[currentnames,currentnames]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = currentadj%*%technoprobas[currentnames,]
semcit = currentadj%*%semprobas[currentnames,]
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=Matrix(res$technoprobas);semprobas=Matrix(res$semprobas)
currentnames=intersect(rownames(technoprobas),rownames(citadjacency))
currentadj = citadjacency[currentnames,currentnames]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = currentadj%*%technoprobas[currentnames,]
semcit = currentadj%*%semprobas[currentnames,]
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=Matrix(as.matrix(res$technoprobas));semprobas=Matrix(as.matrix(res$semprobas))
currentnames=intersect(rownames(technoprobas),rownames(citadjacency))
currentadj = citadjacency[currentnames,currentnames]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = currentadj%*%technoprobas[currentnames,]
semcit = currentadj%*%semprobas[currentnames,]
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
g=ggplot(data.frame(originality=origs,year=cyears,type=types))
library(ggplot2)
g=ggplot(data.frame(originality=origs,year=cyears,type=types))
g+geom_density(aes(x=origs,colour=year,linetype=type))
g=ggplot(data.frame(originality=origs,year=as.character(cyears),type=types))
g+geom_density(aes(x=origs,colour=year,linetype=type))
g=ggplot(data.frame(originality=origs[types=="techno"],year=as.character(cyears[types=="techno"])))
g+geom_density(aes(x=origs,colour=year,linetype=type))
g+geom_density(aes(x=origs,colour=year))
g=ggplot(data.frame(originality=origs[types=="techno"],year=as.character(cyears[types=="techno"])))
g+geom_density(aes(x=origs,colour=year))
g=ggplot(data.frame(originality=origs[types=="techno"],year=as.character(cyears[types=="techno"])))
g+geom_density(aes(x=originality,colour=year))
g=ggplot(data.frame(originality=origs[types=="semantic"],year=as.character(cyears[types=="semantic"])))
g+geom_density(aes(x=originality,colour=year))
head(origs)
length(which(technocit!=0))
length(which(currentadj!=0))
length(which(citadjacency!=0))
origs=c();cyears=c();types=c();
for(year in years){
res = loadProbas(year);technoprobas=res$technoprobas;semprobas=res$semprobas
currentadj = adjacency[rownames(technoprobas),rownames(technoprobas)]
currentadj = diag(rowSums(currentadj))%*%currentadj
technocit = t(technoprobas)%*%(currentadj%*%technoprobas)
semcit = t(semprobas)%*%(currentadj%*%semprobas)
origs = append(origs,1 - rowSums(technocit^2));types=append(types,rep("techno",nrow(technocit)))
origs = append(origs,1 - rowSums(semcit^2));types=append(types,rep("semantic",nrow(semcit)))
cyears=append(cyears,rep(year,nrow(technocit)+nrow(semcit)))
}
